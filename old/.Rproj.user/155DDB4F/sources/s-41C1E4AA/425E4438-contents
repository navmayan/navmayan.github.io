---
title: 'Report: choicepair3'
author: "Yoav Bar-Anan"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    df_print: paged
    theme: flatly
    toc: yes
    toc_float: yes
geometry: left=1cm, right=1cm, top=1cm, bottom=1cm
classoption: landscape
---

<!--
  output:
  pdf_document: 
    fig_crop: no
    fig_height: 3
    fig_width: 4
  word_document: default
geometry: margin=1in

output:
 #rmdformats::readthedown:
  #fig_height: 4
   #fig_width: 10
    #highlight: kate
    #html_document:
     #df_print: paged
  #theme: cerulean
  -->

```{r knitr_init, echo=FALSE, cache=FALSE, warning=FALSE}
library(knitr)
library(rmdformats)
library(tinytex)

## Global options
options(max.print="275")
options(width = 1200)
opts_chunk$set(echo=TRUE, # whether to include R source code in the output file
	             cache=TRUE, 
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               include=TRUE, #whether to include the chunk output in the final output document
               warning=FALSE)
opts_knit$set(width=75)
```

<style type="text/css">
.main-container {
  max-width: 1200px;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{r}
source("C:\\Users\\yoav\\Dropbox\\work\\resources\\stasExamples\\R\\yba.funcs.R")
#The data's folder (directory)
dir = 'C:\\Users\\yoav\\Documents\\bigfiles\\choicepair3'
```

```{r}
allds <- read.csv(paste(dir, "allds.csv", sep="\\"))
allok <- read.csv(paste(dir, "allok.csv", sep="\\"))
```

# Choicepair3: Summary of results


The number of people who passed the consent:
```{r}
my.freq(allds$ord4)
```

The number of people who completed the consent:
```{r}
my.freq(allds$ord16)
```

```{r include=TRUE}
ep.not.ok <- sum(allds$epok==F, na.rm=T)
iatlike.not.ok <- sum(allds$iatlike.ok==F, na.rm=T)
chs.not.ok <- sum(allds$chs.ok==F, na.rm=T)
ind.not.ok <- sum(allds$indok==F, na.rm=T)
exp.not.ok <- sum(allds$expok[!is.na(allds$ord16)]==F, na.rm=T)
chk.not.ok <- sum(allds$chk.ok[!is.na(allds$ord11)]==F, na.rm=T)
ok <- nrow(allok)
```

Excluded: 

* `r ep.not.ok` who had too many error responses in the EP 

* `r exp.not.ok` who did not respond to all direct self-report questions, 

* `r iatlike.not.ok` who had too many errors in the IAT-like induction task
* `r chs.not.ok` who had too many errors in the choice induction task 
* for a toal of `r ind.not.ok` who had too many error responses in at least on induction task

* `r chk.not.ok` who did not respond correctly to all direct comprehension questions, 

In total, `r ok` were ok to include in the analysis.


## Demographics

```{r include=TRUE}
mysum(allok$age)

my.freq(allok$sex)
```

## Self-reported evaluation

Average self-reported liking of the three stimuli of each CS condition
```{r include=TRUE}
mysum.many(exp.cspos + exp.csneg ~ ., dt = allok)
```

```{r include=TRUE}
mlt <- mymelt(dt=allok, formula = exp.cspos + exp.csneg ~ session_id)
my.violin(DV=mlt$value, xFactor = mlt$variable)
```

```{r include=TRUE}
my.violin(DV=mlt$value, xFactor = mlt$variable, points = 'jitter')
```

T-test for the self-report
```{r include=TRUE}
ttestPS(data=allok, pairs=list(list(i1 = 'exp.cspos', i2 = 'exp.csneg')), bf = T, effectSize = T, desc=T)
```


By measure order
```{r include=TRUE}
allok$msrOrd <- ifelse(allok$ord12=='instrate', 'direct.indirect', 
                       ifelse(allok$ord12 =='instep', 'indirect.direct', NA))
my.freq(allok$msrOrd)
mysumBy(exp.cspos + exp.csneg ~ msrOrd, dt = allok)

mlt <- mymelt(dt=allok[!is.na(allok$msrOrd),], formula = exp.cspos + exp.csneg ~ session_id + msrOrd)
my.violin(DV=mlt$value, xFactor = mlt$variable, facet1 = mlt$msrOrd)
```

The effect of the measures order
```{r}
ttestIS(data = allok, vars = c('EC'), group = 'msrOrd', bf=T, desc=T, effectSize=T)
```


Distribution of the diffrence score (the difference between the self-reported liking of CSpos and CSneg)
```{r include=TRUE, dpi=250}
plot.percentile(allok$EC)
```
About 40% showed preference by the co-worker's information, and about 30% showed preference by the pairing.

By specific self-report question
```{r}
mlt <- mymelt(formula = exp.csneg.friendly + exp.cspos.friendly + exp.csneg.skillful + exp.cspos.skillful + exp.csneg.honest + exp.cspos.honest ~ session_id, dt = allok)
mlt$vlnc <- substr(mlt$variable, 7,9)
mlt$qst <- substr(mlt$variable, 11,13)
my.freq(mlt$qst)

my.violin(DV=mlt$value, xFactor = mlt$vlnc, facet1 = mlt$qst)
```

Plot friendly EC
```{r}
plot.percentile(allok$EC.friendly)
```

Plot skillful EC
```{r}
plot.percentile(allok$EC.skillful)
```

Plot honest EC
```{r}
plot.percentile(allok$EC.honest)
```

Repeated measures including the questions.
```{r}
mya <- ezANOVA(data=mlt, dv=value, wid=session_id, within=.(vlnc, qst), type=3, detailed = T, return_aov=T)
anova_out(mya)
```
It does not seem that the questions moderated the effect.

What if we also include those who did not pass the comprehension exam:
```{r}
#All the the conditions for ok, excluding the chkok
all <- allds[which(allds$expok & allds$epok & allds$indok),]
plot.percentile(all$EC)
```
Does not look like much of a change. Let's test the mean
```{r}
ttestPS(data=all, pairs=list(list(i1 = 'exp.cspos', i2 = 'exp.csneg')), bf = T, effectSize = T, desc=T)
```
Decreased from 0.259 to 0.187. Small effects in both cases.

## EP

```{r include=TRUE}
mysum(allok$ep.prf.lrt.D)
```

T-test comparing to zero
```{r include=TRUE}
ttestOneS(data = allok, vars = c('ep.prf.lrt.D'), bf = T, effectSize = T, desc = T)
```
Not a very strong effect, but definitely discrepancy. 

Distribution of the EP score:
```{r include=TRUE, dpi=250}
plot.percentile(allok$ep.prf.lrt.D)
```

By measure order
```{r include=TRUE}
mysumBy(ep.prf.lrt.D ~ msrOrd, dt = allok)
```

T-test for the effect of measures order:
```{r}
ttestIS(data = allok, vars = c('ep.prf.lrt.D'), group = 'msrOrd', bf=T, desc=T, effectSize=T)
```
No significant effect of measures order.

Response latency by prime-target condition
```{r include=TRUE}
mysum.many(formula = ep.csnegneg.rt.m + ep.csnegpos.rt.m + ep.csposneg.rt.m + ep.cspospos.rt.m ~ ., dt = allok)
```
AS usual, the effect is of a very few milliseconds, but that's typical.

The EP score among participants who reported no preference for the cspos
```{r include=TRUE}
ttestOneS(data = allok[allok$EC<=0,], vars = c('ep.prf.lrt.D'), bf = T, effectSize = T, desc = T)
```
We see a rather strong effect even among participants who reported no preference.


# Summary

* Adding a bit of valid information that was opposite to the pairing reversed the self-reported evaluation (d = 0.259; d = 0.187 when adding also participants who did not respond perfectly to the comprehension questionnaire).
  + About 45% of the participants reported preference that reflected the valid information.
  
* However, the EP still reflected the pairing (d = 0.368).
  + About 75% of the participants showed EP preference that reflected the pairing.

* Thus, we found discrepancy between self-reported evaluation and EP. 

* Questions that still bother: 
  + Does the EP reflect automatic evaluation? In the next study we will try to measures speeded self-report in an attempt to investigate that question.
  + Was the validity information substential enough, or perhaps the self-report evaluation did not reflect actual evaluation; only comprehension of the presumably valid information.
  + Most participants did not report preference by the valid information, but more reported that preference than preferenc by pairing (about 20% reported no preference).
  

